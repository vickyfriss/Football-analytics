{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4703437a-4581-443d-b88a-8fc5d12559b9",
   "metadata": {},
   "source": [
    "## Scraping & Verifying HYROX Results Across Seasons\n",
    "\n",
    "**Competitions:** HYROX Seasons 1‚Äì8 (Official Results Portal)  \n",
    "**Purpose:** Scrape all available race results and verify that every race, division, and gender has been successfully collected  \n",
    "**Methods:** Selenium automation, controlled multi-threading, dynamic pagination handling, structured CSV export, division detection, empty-file tracking, and race-level completeness checks  \n",
    "**Author:** [Victoria Friss de Kereki](https://www.linkedin.com/in/victoria-friss-de-kereki/)  \n",
    "\n",
    "---\n",
    "\n",
    "**Notebook first written:** `23/02/2026`  \n",
    "**Last updated:** `27/02/2026`  \n",
    "\n",
    "> This notebook builds a **robust scraping and verification pipeline** for HYROX competition results.\n",
    "> \n",
    "> The workflow:\n",
    "> \n",
    "> - üåê Scrapes race results directly from the official HYROX results platform  \n",
    "> - üóÇ Organises outputs by **Season, Race, and Division**  \n",
    "> - üîÑ Handles dynamic page loading and pagination safely  \n",
    "> - üìÅ Saves structured CSV files for each race-division combination  \n",
    "> - ‚ö†Ô∏è Tracks empty divisions and failed scrapes  \n",
    "> - üèÅ Verifies that every race includes all the available divisions\n",
    "> \n",
    "> The objective of this notebook is to ensure **complete and reliable data extraction**, creating a solid foundation for downstream cleaning, validation, and analytical modelling in subsequent notebooks.\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ae46c-788b-442b-aec2-9f717e2392a2",
   "metadata": {},
   "source": [
    "### Scrape many at a time, for seasons and divisions available, even the empty ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418c458-8cfa-41c9-9ada-8af3f467bf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "BASE_URLS = {\n",
    "    f\"Season_{i}\": f\"https://results.hyrox.com/season-{i}/\"\n",
    "    for i in range(1, 9)\n",
    "}\n",
    "\n",
    "SAVE_ROOT = r\"Datasets\\Hyrox\"\n",
    "\n",
    "MAX_THREADS = 20\n",
    "MAX_RETRIES_PER_GENDER = 3\n",
    "MAX_RETRIES_PER_DIVISION = 2\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def human_pause(a=2, b=4):\n",
    "    time.sleep(random.uniform(a, b))\n",
    "\n",
    "\n",
    "def safe_filename(text):\n",
    "    return text.replace(\" \", \"_\").replace(\"/\", \"-\").replace(\",\", \"\")\n",
    "\n",
    "\n",
    "def create_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "def log_message(season, race, division=None, gender=None, message=\"\"):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    season_race = f\"[{season} - {race}]\"\n",
    "    division_part = f\"[{division}]\" if division else \"\"\n",
    "    gender_part = f\"[{gender}]\" if gender else \"\"\n",
    "    print(f\"{now} {season_race}{division_part}{gender_part} {message}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SELECT CONTEXT\n",
    "# ============================================================\n",
    "\n",
    "def select_context(driver, base_url, race_value, division=None, gender=None):\n",
    "    driver.get(base_url)\n",
    "    human_pause()\n",
    "\n",
    "    Select(driver.find_element(By.ID, \"default-lists-event_main_group\"))\\\n",
    "        .select_by_value(race_value)\n",
    "\n",
    "    if division:\n",
    "        Select(driver.find_element(By.ID, \"default-lists-event\"))\\\n",
    "            .select_by_visible_text(division)\n",
    "\n",
    "    if gender:\n",
    "        Select(driver.find_element(By.ID, \"default-lists-sex\"))\\\n",
    "            .select_by_value(gender)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SCRAPE PAGES\n",
    "# ============================================================\n",
    "\n",
    "def scrape_pages(driver, season, race_name, division, gender_label, results):\n",
    "\n",
    "    page_number = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 25).until(\n",
    "                lambda d:\n",
    "                \"There are currently no results available\" in d.page_source\n",
    "                or len(d.find_elements(By.CSS_SELECTOR, \"li.list-group-item.row\")) > 1\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            log_message(season, race_name, division, gender_label,\n",
    "                        \"TIMEOUT - retrying\")\n",
    "            return \"failed\"\n",
    "\n",
    "        if \"There are currently no results available\" in driver.page_source:\n",
    "            return \"empty\"\n",
    "\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"li.list-group-item.row\")\n",
    "        rows = [r for r in rows if \"list-group-header\" not in r.get_attribute(\"class\")]\n",
    "\n",
    "        if not rows:\n",
    "            return \"failed\"\n",
    "\n",
    "        for row in rows:\n",
    "            try:\n",
    "                rank = row.find_element(By.CSS_SELECTOR, \".place-primary\").text\n",
    "\n",
    "                name_elements = row.find_elements(By.CSS_SELECTOR, \"h4.type-fullname\")\n",
    "                name = name_elements[0].text if name_elements else \"\"\n",
    "\n",
    "                nation_elements = row.find_elements(By.CSS_SELECTOR, \".nation__abbr\")\n",
    "                nation = nation_elements[0].text if nation_elements else \"\"\n",
    "\n",
    "                age_group_elements = row.find_elements(By.CSS_SELECTOR, \".type-age_class\")\n",
    "                age_group = (\n",
    "                    age_group_elements[0].text.replace(\"Age Group\", \"\").strip()\n",
    "                    if age_group_elements else \"\"\n",
    "                )\n",
    "\n",
    "                total_time_elements = row.find_elements(By.CSS_SELECTOR, \".type-time\")\n",
    "                total_time = (\n",
    "                    total_time_elements[0].text.replace(\"Total\", \"\").strip()\n",
    "                    if total_time_elements else \"\"\n",
    "                )\n",
    "\n",
    "                results.append([\n",
    "                    race_name, division, gender_label,\n",
    "                    rank, name, nation,\n",
    "                    age_group, total_time\n",
    "                ])\n",
    "\n",
    "            except Exception:\n",
    "                return \"failed\"\n",
    "\n",
    "        log_message(season, race_name, division, gender_label,\n",
    "                    f\"Page {page_number} scraped\")\n",
    "\n",
    "        page_number += 1\n",
    "\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//a[text()='>']\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            human_pause()\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "    return \"complete\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SCRAPE ONE RACE\n",
    "# ============================================================\n",
    "\n",
    "def scrape_race(season, base_url, race_name, race_value):\n",
    "\n",
    "    driver = create_driver()\n",
    "    season_folder = os.path.join(SAVE_ROOT, season)\n",
    "    os.makedirs(season_folder, exist_ok=True)\n",
    "\n",
    "    safe_race = safe_filename(race_name)\n",
    "\n",
    "    log_message(season, race_name, message=\"Scraping started\")\n",
    "\n",
    "    select_context(driver, base_url, race_value)\n",
    "\n",
    "    division_dropdown = Select(driver.find_element(By.ID, \"default-lists-event\"))\n",
    "    divisions = [o.text for o in division_dropdown.options]\n",
    "\n",
    "    for division in divisions:\n",
    "\n",
    "        file_path = os.path.join(\n",
    "            season_folder,\n",
    "            f\"{safe_race}_{safe_filename(division)}.csv\"\n",
    "        )\n",
    "\n",
    "        # ===================================================\n",
    "        # SKIP IF CSV EXISTS\n",
    "        # ===================================================\n",
    "        if os.path.exists(file_path):\n",
    "            log_message(season, race_name, division,\n",
    "                        message=\"Skipped (CSV already exists)\")\n",
    "            continue\n",
    "\n",
    "        log_message(season, race_name, division, message=\"Division started\")\n",
    "\n",
    "        division_success = False\n",
    "        division_results = []\n",
    "\n",
    "        for division_attempt in range(1, MAX_RETRIES_PER_DIVISION + 1):\n",
    "\n",
    "            log_message(season, race_name, division,\n",
    "                        message=f\"Division attempt {division_attempt}\")\n",
    "\n",
    "            select_context(driver, base_url, race_value, division=division)\n",
    "\n",
    "            try:\n",
    "                gender_dropdown = Select(driver.find_element(By.ID, \"default-lists-sex\"))\n",
    "                genders = [(o.get_attribute(\"value\"), o.text)\n",
    "                           for o in gender_dropdown.options]\n",
    "            except NoSuchElementException:\n",
    "                genders = [(\"\", \"All\")]\n",
    "\n",
    "            division_failed = False\n",
    "\n",
    "            for gender_code, gender_label in genders:\n",
    "\n",
    "                gender_success = False\n",
    "\n",
    "                for gender_attempt in range(1, MAX_RETRIES_PER_GENDER + 1):\n",
    "\n",
    "                    log_message(season, race_name, division, gender_label,\n",
    "                                f\"Gender attempt {gender_attempt}\")\n",
    "\n",
    "                    select_context(\n",
    "                        driver,\n",
    "                        base_url,\n",
    "                        race_value,\n",
    "                        division=division,\n",
    "                        gender=gender_code if gender_code else None\n",
    "                    )\n",
    "\n",
    "                    Select(driver.find_element(By.ID, \"default-num_results\"))\\\n",
    "                        .select_by_value(\"100\")\n",
    "\n",
    "                    driver.find_element(By.ID, \"default-submit\").click()\n",
    "                    human_pause()\n",
    "\n",
    "                    temp_results = []\n",
    "\n",
    "                    status = scrape_pages(\n",
    "                        driver,\n",
    "                        season,\n",
    "                        race_name,\n",
    "                        division,\n",
    "                        gender_label,\n",
    "                        temp_results\n",
    "                    )\n",
    "\n",
    "                    if status in [\"complete\", \"empty\"]:\n",
    "                        division_results.extend(temp_results)\n",
    "                        gender_success = True\n",
    "                        break\n",
    "\n",
    "                    log_message(season, race_name, division, gender_label,\n",
    "                                \"Retrying gender\")\n",
    "\n",
    "                if not gender_success:\n",
    "                    division_failed = True\n",
    "                    break\n",
    "\n",
    "            if not division_failed:\n",
    "                division_success = True\n",
    "                break\n",
    "\n",
    "            log_message(season, race_name, division,\n",
    "                        \"Retrying entire division\")\n",
    "\n",
    "        # ===================================================\n",
    "        # SAVE ALWAYS (even if empty)\n",
    "        # ===================================================\n",
    "\n",
    "        if not division_success:\n",
    "            log_message(season, race_name, division,\n",
    "                        \"Division failed after retries ‚Äî saving empty CSV\")\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            division_results,\n",
    "            columns=[\n",
    "                \"Race\", \"Division\", \"Gender\",\n",
    "                \"Rank Overall\", \"Name\", \"Nation\",\n",
    "                \"Age Group\", \"Total Time\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        log_message(season, race_name, division,\n",
    "                    message=f\"CSV saved ({len(df)} rows)\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    log_message(season, race_name, message=\"Race completed\")\n",
    "    return f\"{season} - {race_name} DONE\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "all_tasks = []\n",
    "\n",
    "for season, base_url in BASE_URLS.items():\n",
    "\n",
    "    driver_main = create_driver()\n",
    "    driver_main.get(base_url)\n",
    "    human_pause()\n",
    "\n",
    "    race_dropdown = Select(\n",
    "        driver_main.find_element(By.ID, \"default-lists-event_main_group\")\n",
    "    )\n",
    "\n",
    "    races = [\n",
    "        (opt.text.strip(), opt.get_attribute(\"value\"))\n",
    "        for opt in race_dropdown.options\n",
    "    ]\n",
    "\n",
    "    driver_main.quit()\n",
    "\n",
    "    for race_name, race_value in races:\n",
    "        all_tasks.append((season, base_url, race_name, race_value))\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    futures = [executor.submit(scrape_race, *task)\n",
    "               for task in all_tasks]\n",
    "\n",
    "    for f in futures:\n",
    "        print(f.result())\n",
    "\n",
    "\n",
    "print(\"\\nALL SEASONS COMPLETE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cb83f-ceb4-4989-8140-d6f0a5bb2c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf61c30-123b-4106-a61e-eb049ef40dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c7a28b-16b1-4213-9b5f-691136e63913",
   "metadata": {},
   "source": [
    "### Check all existing seasons/races/divisions have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fbea2-3fc1-4a36-97d7-c16a9f12e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "\n",
    "BASE_URLS = {f\"Season_{i}\": f\"https://results.hyrox.com/season-{i}/\" for i in range(1, 9)}\n",
    "SAVE_ROOT = r\"Datasets\\Hyrox\"\n",
    "\n",
    "# ==========================\n",
    "# DRIVER\n",
    "# ==========================\n",
    "\n",
    "def create_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "# ==========================\n",
    "# VERIFICATION\n",
    "# ==========================\n",
    "\n",
    "def verify_all_downloads():\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"VERIFYING HYROX DATASET\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for season, base_url in BASE_URLS.items():\n",
    "\n",
    "        print(f\"\\n========== CHECKING {season} ==========\")\n",
    "\n",
    "        season_folder = os.path.join(SAVE_ROOT, season)\n",
    "\n",
    "        if not os.path.exists(season_folder):\n",
    "            print(f\"‚ùå Season folder missing: {season}\")\n",
    "            continue\n",
    "\n",
    "        local_files = set(os.listdir(season_folder))\n",
    "\n",
    "        driver = create_driver()\n",
    "        driver.get(base_url)\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                \n",
    "                EC.presence_of_element_located((By.ID, \"default-lists-event_main_group\"))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(f\"‚ùå Could not load season page: {season}\")\n",
    "            driver.quit()\n",
    "            continue\n",
    "\n",
    "        race_dropdown = Select(driver.find_element(By.ID, \"default-lists-event_main_group\"))\n",
    "        races = [(opt.text.strip(), opt.get_attribute(\"value\"))\n",
    "                 for opt in race_dropdown.options]\n",
    "\n",
    "        missing_races = []\n",
    "        missing_divisions = []\n",
    "\n",
    "        for race_name, race_value in races:\n",
    "\n",
    "            safe_race = race_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "\n",
    "            print(f\"Checking race: {race_name}\")\n",
    "\n",
    "            driver.get(base_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            Select(driver.find_element(By.ID, \"default-lists-event_main_group\"))\\\n",
    "                .select_by_value(race_value)\n",
    "            time.sleep(2)\n",
    "\n",
    "            division_dropdown = Select(driver.find_element(By.ID, \"default-lists-event\"))\n",
    "            divisions = [opt.text.strip() for opt in division_dropdown.options]\n",
    "\n",
    "            race_files = [f for f in local_files if f.startswith(safe_race + \"_\")]\n",
    "\n",
    "            if not race_files:\n",
    "                missing_races.append(race_name)\n",
    "\n",
    "            race_missing_divs = []\n",
    "\n",
    "            for div in divisions:\n",
    "                safe_div = div.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "                expected_filename = f\"{safe_race}_{safe_div}.csv\"\n",
    "\n",
    "                if expected_filename not in local_files:\n",
    "                    race_missing_divs.append(div)\n",
    "\n",
    "            if race_missing_divs:\n",
    "                missing_divisions.append((race_name, race_missing_divs))\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        # REPORT\n",
    "        if not missing_races:\n",
    "            print(\"‚úÖ No missing races.\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Missing races:\")\n",
    "            for r in missing_races:\n",
    "                print(f\"   - {r}\")\n",
    "\n",
    "        if not missing_divisions:\n",
    "            print(\"‚úÖ All divisions present.\")\n",
    "        else:\n",
    "            print(\"\\n‚ö† Missing divisions:\")\n",
    "            for race, divs in missing_divisions:\n",
    "                print(f\"\\n  {race}\")\n",
    "                for d in divs:\n",
    "                    print(f\"     - {d}\")\n",
    "\n",
    "        print(f\"\\n========== DONE {season} ==========\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"VERIFICATION COMPLETE\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "# ==========================\n",
    "# RUN\n",
    "# ==========================\n",
    "\n",
    "verify_all_downloads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c48a6-c928-4801-8811-cd277858ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# STEP 3: Validate Empty Files Coverage\n",
    "# ---------------------------------\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\"EMPTY FILE VALIDATION\")\n",
    "print(\"============================\")\n",
    "\n",
    "# Map base race+division ‚Üí files with data\n",
    "coverage_map = defaultdict(list)\n",
    "\n",
    "for division, files in division_files.items():\n",
    "\n",
    "    for file_path, filename_without_ext, season in files:\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            # Remove day/overall suffix for base grouping\n",
    "            base_name = re.sub(r\"_(OVERALL|SATURDAY|SUNDAY|FRIDAY|THURSDAY|WEDNESDAY)$\",\n",
    "                               \"\",\n",
    "                               filename_without_ext.upper())\n",
    "\n",
    "            coverage_map[base_name].append(filename_without_ext)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "problems_found = False\n",
    "\n",
    "for empty_file in empty_files_detected:\n",
    "\n",
    "    empty_upper = empty_file.upper()\n",
    "\n",
    "    base_name = re.sub(r\"_(OVERALL|SATURDAY|SUNDAY|FRIDAY|THURSDAY|WEDNESDAY)$\",\n",
    "                       \"\",\n",
    "                       empty_upper)\n",
    "\n",
    "    if base_name in coverage_map and len(coverage_map[base_name]) > 0:\n",
    "        print(f\"‚úÖ OK: {empty_file} is empty but covered by:\")\n",
    "        for alt in coverage_map[base_name]:\n",
    "            print(f\"   ‚Ü≥ {alt}\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISSING DATA: {empty_file} has no alternative dataset with data\")\n",
    "        problems_found = True\n",
    "\n",
    "if not empty_files_detected:\n",
    "    print(\"No empty files to validate.\")\n",
    "\n",
    "elif not problems_found:\n",
    "    print(\"\\nAll empty files are safely covered by alternative datasets.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö† Some races/divisions are completely missing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef42223-73f3-4adb-ae3f-16389ee0c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_folder = r\"Datasets\\Hyrox\"\n",
    "\n",
    "deleted_files = []\n",
    "failed_files = []\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\"DELETING EMPTY CSV FILES\")\n",
    "print(\"============================\")\n",
    "\n",
    "for subdir, _, files in os.walk(root_folder):\n",
    "\n",
    "    # Skip processed dataset folder\n",
    "    if \"processed dataset\" in subdir.lower():\n",
    "        continue\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(subdir, file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            if df.empty:\n",
    "                os.remove(file_path)\n",
    "                deleted_files.append(file_path)\n",
    "                print(f\"üóë Deleted: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_files.append((file_path, str(e)))\n",
    "\n",
    "# ---------------------------------\n",
    "# SUMMARY\n",
    "# ---------------------------------\n",
    "print(\"\\n============================\")\n",
    "print(\"DELETION SUMMARY\")\n",
    "print(\"============================\")\n",
    "\n",
    "print(f\"Total empty files deleted: {len(deleted_files)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(\"\\nFiles that could not be processed:\")\n",
    "    for path, error in failed_files:\n",
    "        print(f\"- {path} ({error})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f3f02-b922-49c4-8e37-3314ae1fe9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "root_folder = r\"Datasets\\Hyrox\"\n",
    "output_folder = os.path.join(root_folder, \"Processed dataset\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "division_files = defaultdict(list)\n",
    "division_datasets = {}\n",
    "\n",
    "suffix_words = {\n",
    "    \"overall\", \"saturday\", \"sunday\", \"friday\",\n",
    "    \"thursday\", \"wednesday\"\n",
    "}\n",
    "\n",
    "# ---------------------------------\n",
    "# STEP 1: Group files by division\n",
    "# ---------------------------------\n",
    "for subdir, _, files in os.walk(root_folder):\n",
    "\n",
    "    # Skip processed dataset folder\n",
    "    if \"processed dataset\" in subdir.lower():\n",
    "        continue\n",
    "\n",
    "    season = os.path.basename(subdir)\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        filename_without_ext = file.replace(\".csv\", \"\")\n",
    "\n",
    "        # Skip generic names if they exist\n",
    "        if filename_without_ext.lower() in [\"doubles\", \"singles\", \"hyrox_pro\"]:\n",
    "            continue\n",
    "\n",
    "        parts = filename_without_ext.split(\"_\")\n",
    "\n",
    "        # Find all occurrences of \"hyrox\"\n",
    "        hyrox_indices = [i for i, p in enumerate(parts) if p.lower() == \"hyrox\"]\n",
    "\n",
    "        if not hyrox_indices:\n",
    "            continue\n",
    "\n",
    "        # Take LAST occurrence (fixes London issue)\n",
    "        hyrox_index = hyrox_indices[-1]\n",
    "\n",
    "        division_parts = parts[hyrox_index:]\n",
    "\n",
    "        # Remove unwanted suffixes\n",
    "        while division_parts and division_parts[-1].lower() in suffix_words:\n",
    "            division_parts = division_parts[:-1]\n",
    "\n",
    "        division = \"_\".join(division_parts)\n",
    "\n",
    "        # Standardise formatting\n",
    "        division = division.upper()\n",
    "        division = division.replace(\"-\", \"_\")\n",
    "        division = re.sub(r\"_+$\", \"\", division)\n",
    "        division = re.sub(r\"_+\", \"_\", division)\n",
    "\n",
    "        file_path = os.path.join(subdir, file)\n",
    "\n",
    "        division_files[division].append((file_path, filename_without_ext, season))\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# STEP 2: Create dataset per division\n",
    "# ---------------------------------\n",
    "for division, files in division_files.items():\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for file_path, filename_without_ext, season in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            if df.empty:\n",
    "                continue   # Just skip empty files silently\n",
    "\n",
    "            df[\"source_file\"] = filename_without_ext\n",
    "            df[\"Season\"] = season\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f\"{division}.csv\")\n",
    "        combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "        division_datasets[division] = combined_df\n",
    "        globals()[division] = combined_df\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# FINAL SUMMARY\n",
    "# ---------------------------------\n",
    "print(\"\\n============================\")\n",
    "print(\"DATASETS CREATED\")\n",
    "print(\"============================\")\n",
    "\n",
    "if division_datasets:\n",
    "    for name in sorted(division_datasets.keys()):\n",
    "        print(f\"{name} ‚Üí {len(division_datasets[name])} rows\")\n",
    "else:\n",
    "    print(\"No datasets created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b28bd-e6c7-4d7c-a805-eacb4b48b286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
